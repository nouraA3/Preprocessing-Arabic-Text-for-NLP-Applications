{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# step 1"
      ],
      "metadata": {
        "id": "8pnMnJXm6agv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v38MRleKnQnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d4f823-6730-4203-b00a-233d67fc3be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: camel-tools in /usr/local/lib/python3.11/dist-packages (1.5.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.17.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.6.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from camel-tools) (5.5.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.6.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.3.9)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers<4.44.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (4.43.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.32.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.14.1)\n",
            "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.20.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from camel-tools) (4.67.1)\n",
            "Requirement already satisfied: muddler in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.1.3)\n",
            "Requirement already satisfied: camel-kenlm>=2024.5.6 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2024.5.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->camel-tools) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->camel-tools) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.5.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->camel-tools) (3.0.2)\n",
            "Usage:\n",
            "    camel_data (-i | --install) [-f | --force] <PACKAGE>\n",
            "    camel_data (-p | --post-install) <PACKAGE> <ARGS>...\n",
            "    camel_data (-l | --list)\n",
            "    camel_data (-u | --update)\n",
            "    camel_data (-v | --version)\n",
            "    camel_data (-h | --help)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.11/dist-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farasapy) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farasapy) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#import Necessary Libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "!pip install camel-tools\n",
        "!camel_data full\n",
        "!pip install -U farasapy\n",
        "\n",
        "\n",
        "from farasa.pos import FarasaPOSTagger\n",
        "from farasa.ner import FarasaNamedEntityRecognizer\n",
        "from farasa.diacratizer import FarasaDiacritizer\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "from farasa.stemmer import FarasaStemmer as stemmer\n",
        "\n",
        "# Import the dediac_ar function from camel_tools to remove diacritics (Tashkeel)\n",
        "from camel_tools.utils.dediac import dediac_ar\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Import the stopwords module\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2"
      ],
      "metadata": {
        "id": "NNLU72YwzEC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/ArSarcasm_train.csv')\n",
        "# Inspect the dataset\n",
        "print(\"Original Dataset:\")\n",
        "print(df.head()) #shows the fisrt 5 rows\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info()) #shows the data information"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6rYieX-0nCP",
        "outputId": "e10c7f80-d73f-44d4-af9c-f5785dc08940"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "  dialect  sarcasm sentiment original_sentiment  \\\n",
            "0    gulf    False  negative           negative   \n",
            "1     msa    False   neutral           positive   \n",
            "2   egypt    False   neutral            neutral   \n",
            "3  levant     True   neutral           negative   \n",
            "4     msa    False   neutral           negative   \n",
            "\n",
            "                                               tweet   source  \n",
            "0  \"Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ ...  semeval  \n",
            "1  \"#Ù†Ø§Ø¯ÙŠÙ†_Ù†Ø³ÙŠØ¨_Ù†Ø¬ÙŠÙ… â¤ï¸â¤ï¸â¤ï¸Ù…Ø¬Ù„Ø© #Ù…Ø§Ø±ÙŠ_ÙƒÙ„ÙŠØ± ğŸ’­#Ù…Ù„ÙƒØ©...  semeval  \n",
            "2                      \"@Alito_NBA Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\"  semeval  \n",
            "3     \"@KSA24 ÙŠØ¹Ù†ÙŠ \"Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§\" Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\"  semeval  \n",
            "4  \"RT @alaahmad20: Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„...  semeval  \n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8437 entries, 0 to 8436\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             8437 non-null   object\n",
            " 1   sarcasm             8437 non-null   bool  \n",
            " 2   sentiment           8437 non-null   object\n",
            " 3   original_sentiment  8437 non-null   object\n",
            " 4   tweet               8437 non-null   object\n",
            " 5   source              8437 non-null   object\n",
            "dtypes: bool(1), object(5)\n",
            "memory usage: 337.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 3"
      ],
      "metadata": {
        "id": "dCgt1_Dx18pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_text(text):\n",
        "    # Replace underscore with a space\n",
        "    text = text.replace('_', ' ')\n",
        "    # Remove non-Arabic characters\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "    # Remove Tatweel\n",
        "    text = text.replace('Ù€', '')\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "#  Apply normalization to the 'tweet' column\n",
        "df['tweet'] = df['tweet'].apply(normalize_text)\n",
        "print(\"After Normalization:\")\n",
        "print(df['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B6X7gjk1yqf",
        "outputId": "9f94da5f-1852-4449-9d6c-414d35cbfe93"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Normalization:\n",
            "0    Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ùƒ...\n",
            "1          Ù†Ø§Ø¯ÙŠÙ† Ù†Ø³ÙŠØ¨ Ù†Ø¬ÙŠÙ… Ù…Ø¬Ù„Ø© Ù…Ø§Ø±ÙŠ ÙƒÙ„ÙŠØ± Ù…Ù„ÙƒØ© Ø§Ù„ØµØ­Ø±Ø§Ø¡\n",
            "2                                     Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\n",
            "3                  ÙŠØ¹Ù†ÙŠ Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§ Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\n",
            "4    Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø³ÙŠØ·Ø±Ø© Ø§Ù„Ø£Ù…Ù†ÙŠØ© ÙÙŠ ...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 4"
      ],
      "metadata": {
        "id": "_GJO7GFt2eFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to remove diacritics from Arabic text\n",
        "def remove_diacritics(text):\n",
        " # Use dediac_ar to strip diacritics from the input text\n",
        "    return dediac_ar(text)\n",
        "\n",
        "# Apply the diacritic removal function to the 'tweet' column in the dataset\n",
        "df['tweet'] = df['tweet'].apply(remove_diacritics)\n",
        "\n",
        "# Print the first few rows of the 'tweet' column after removing diacritics\n",
        "print(\"After Removing Diacritics:\")\n",
        "print(df['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQp8QaHT2flM",
        "outputId": "b1aff8a2-f0d6-4a83-c088-fd9715be94e6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Removing Diacritics:\n",
            "0    Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ùƒ...\n",
            "1          Ù†Ø§Ø¯ÙŠÙ† Ù†Ø³ÙŠØ¨ Ù†Ø¬ÙŠÙ… Ù…Ø¬Ù„Ø© Ù…Ø§Ø±ÙŠ ÙƒÙ„ÙŠØ± Ù…Ù„ÙƒØ© Ø§Ù„ØµØ­Ø±Ø§Ø¡\n",
            "2                                     Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\n",
            "3                  ÙŠØ¹Ù†ÙŠ Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§ Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\n",
            "4    Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø³ÙŠØ·Ø±Ø© Ø§Ù„Ø£Ù…Ù†ÙŠØ© ÙÙŠ ...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 6"
      ],
      "metadata": {
        "id": "uih9jufu2tGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load Arabic stopwords from NLTK\n",
        "arabic_stopwords = set(stopwords.words('arabic'))\n",
        "\n",
        "# Define the stopword removal function\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    filtered_words = [word for word in words if word not in arabic_stopwords]  # Filter stopwords\n",
        "    return ' '.join(filtered_words)  # Rejoin the filtered words into a string\n",
        "\n",
        "# Apply the function to the 'tweet' column\n",
        "df['tweet'] = df['tweet'].apply(remove_stopwords)\n",
        "\n",
        "# Display the cleaned text\n",
        "print(\"After Removing Stopwords:\")\n",
        "print(df['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HonffwcrGzr7",
        "outputId": "571c1e58-29bf-45b2-d5d8-3e3e2e3fa39f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Removing Stopwords:\n",
            "0    Ù†ØµÙŠØ­Ù‡ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ ÙƒÙ†Ø§ Ù…ØªÙˆ...\n",
            "1          Ù†Ø§Ø¯ÙŠÙ† Ù†Ø³ÙŠØ¨ Ù†Ø¬ÙŠÙ… Ù…Ø¬Ù„Ø© Ù…Ø§Ø±ÙŠ ÙƒÙ„ÙŠØ± Ù…Ù„ÙƒØ© Ø§Ù„ØµØ­Ø±Ø§Ø¡\n",
            "2                                     Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\n",
            "3                  ÙŠØ¹Ù†ÙŠ Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§ Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\n",
            "4    Ù‚Ø§Ø¦Ø¯ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø³ÙŠØ·Ø±Ø© Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø´Ø±Ù‚ÙŠ Ùˆ...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test dataset"
      ],
      "metadata": {
        "id": "vaY2uWXi6o3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2"
      ],
      "metadata": {
        "id": "VRLHlXEKBxzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "\n",
        "df1 = pd.read_csv('/content/ArSarcasm_test.csv')\n"
      ],
      "metadata": {
        "id": "eAuZ4GkL6rbQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the dataset\n",
        "print(\"Original Dataset:\")\n",
        "print(df1.head()) #shows the fisrt 5 rows\n",
        "print(\"Dataset Info:\")\n",
        "print(df1.info()) #shows the data information"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICET7zYn8e9t",
        "outputId": "7fd6e69b-5138-465f-89f0-64bf5a17330a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "  dialect  sarcasm sentiment original_sentiment  \\\n",
            "0     msa     True  negative           negative   \n",
            "1    gulf    False  positive            neutral   \n",
            "2     msa     True   neutral            neutral   \n",
            "3     msa    False   neutral            neutral   \n",
            "4     msa    False   neutral            neutral   \n",
            "\n",
            "                                               tweet   source  \n",
            "0  \"@AbuEmad74241481 @Cesars2014 Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ ...  semeval  \n",
            "1  \"RT @JannetForster: Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù… ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ...  semeval  \n",
            "2             Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†     astd  \n",
            "3  \"@EGYPTAIR Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§Ù‹ Ø§Ù†ÙŠ ÙÙŠ ...  semeval  \n",
            "4  Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­...  semeval  \n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2110 entries, 0 to 2109\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             2110 non-null   object\n",
            " 1   sarcasm             2110 non-null   bool  \n",
            " 2   sentiment           2110 non-null   object\n",
            " 3   original_sentiment  2110 non-null   object\n",
            " 4   tweet               2110 non-null   object\n",
            " 5   source              2110 non-null   object\n",
            "dtypes: bool(1), object(5)\n",
            "memory usage: 84.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 3"
      ],
      "metadata": {
        "id": "Tb8CDv4Y9EaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_text(text):\n",
        "    # Replace underscore with a space\n",
        "    text = text.replace('_', ' ')\n",
        "    # Remove non-Arabic characters\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "    # Remove Tatweel\n",
        "    text = text.replace('Ù€', '')\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply normalization to the 'tweet' column\n",
        "df1['tweet'] = df1['tweet'].apply(normalize_text)\n",
        "print(\"After Normalization:\")\n",
        "print(df1['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JGgqJXU9F0H",
        "outputId": "c4e2bf58-838a-497a-cef7-55195c586012"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Normalization:\n",
            "0    Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ Ø­Ø·Ù…ÙˆØ§ Ø§Ø³Ø·ÙˆØ±Ø© Ø§Ù„Ù…ÙŠØ±ÙƒØ§ÙØ§ Ø§Ù„Ø§Ø³Ø±Ø§Ø¦...\n",
            "1    Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù… ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ØªØ±Ø§ Ø±Ù…Ø¶Ø§Ù† Ù‚Ø±Ø¨ Ùˆ Ø§Ù„ÙˆÙ‚...\n",
            "2               Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†\n",
            "3    Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§Ù‹ Ø§Ù†ÙŠ ÙÙŠ Ø¨Ø±ÙˆÙƒØ³ÙŠÙ„ Ùˆ Ø§...\n",
            "4    Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 4"
      ],
      "metadata": {
        "id": "11xnjmxA9YRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to remove diacritics from Arabic text\n",
        "def remove_diacritics(text):\n",
        " # Use dediac_ar to strip diacritics from the input text\n",
        "    return dediac_ar(text)\n",
        "\n",
        "# Apply the diacritic removal function to the 'tweet' column in the dataset\n",
        "df1['tweet'] = df1['tweet'].apply(remove_diacritics)\n",
        "\n",
        "# Print the first few rows of the 'tweet' column after removing diacritics\n",
        "print(\"After Removing Diacritics:\")\n",
        "print(df1['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc2b_C_B9ZST",
        "outputId": "3d5a8025-c1d0-426c-9565-1b61b37f0b70"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Removing Diacritics:\n",
            "0    Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ Ø­Ø·Ù…ÙˆØ§ Ø§Ø³Ø·ÙˆØ±Ø© Ø§Ù„Ù…ÙŠØ±ÙƒØ§ÙØ§ Ø§Ù„Ø§Ø³Ø±Ø§Ø¦...\n",
            "1    Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù… ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ØªØ±Ø§ Ø±Ù…Ø¶Ø§Ù† Ù‚Ø±Ø¨ Ùˆ Ø§Ù„ÙˆÙ‚...\n",
            "2               Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†\n",
            "3    Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§ Ø§Ù†ÙŠ ÙÙŠ Ø¨Ø±ÙˆÙƒØ³ÙŠÙ„ Ùˆ Ø§Ø±...\n",
            "4    Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 6"
      ],
      "metadata": {
        "id": "3Xt3CPNg9p3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Arabic stopwords from NLTK\n",
        "arabic_stopwords = set(stopwords.words('arabic'))\n",
        "\n",
        "# Define the stopword removal function\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    filtered_words = [word for word in words if word not in arabic_stopwords]  # Filter stopwords\n",
        "    return ' '.join(filtered_words)  # Rejoin the filtered words into a string\n",
        "\n",
        "# Apply the function to the 'tweet' column\n",
        "df1['tweet'] = df1['tweet'].apply(remove_stopwords)\n",
        "\n",
        "# Display the cleaned text\n",
        "print(\"After Removing Stopwords:\")\n",
        "print(df1['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FBsK8yD9s63",
        "outputId": "a47366b7-b245-4815-8e80-7339f39d5b2f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Removing Stopwords:\n",
            "0    Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ Ø­Ø·Ù…ÙˆØ§ Ø§Ø³Ø·ÙˆØ±Ø© Ø§Ù„Ù…ÙŠØ±ÙƒØ§ÙØ§ Ø§Ù„Ø§Ø³Ø±Ø§Ø¦...\n",
            "1    Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ØªØ±Ø§ Ø±Ù…Ø¶Ø§Ù† Ù‚Ø±Ø¨ Ø§Ù„ÙˆÙ‚Øª Ù‚Ù„...\n",
            "2               Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†\n",
            "3    Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§ Ø§Ù†ÙŠ Ø¨Ø±ÙˆÙƒØ³ÙŠÙ„ Ø§Ø±ÙŠØ¯ Ø§Ù„...\n",
            "4    ØªØ±Ø§Ù‡ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù‡ÙŠÙ„Ø§Ø±ÙŠ ÙƒÙ„Ù†Øª...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    }
  ]
}